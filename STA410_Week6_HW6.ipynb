{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c83339c",
   "metadata": {},
   "source": [
    "# STA410 Week 6 Homework (4 points)\n",
    "\n",
    "Due 12 PM Feb 14 (before class starts)\n",
    "\n",
    "\n",
    "1. **Paired or individual assignment.** Work may be shared within pairs without restriction, but collaborations beyond the pairs must be limited to \"hints\" and may not share complete solutions.\n",
    "\n",
    "\n",
    "2. You are encouraged to adapt code you find available online **(including using AI chat bot suppport tools)** into your notebook; however, if you do so please provide a link to the utilized resource. ***If you don't and multiple students have the same answer an academic integrity proceeding may be undertaken.***  \n",
    "\n",
    "\n",
    "3. **Library imports are limited** to only libraries imported in the starter code and the [standard python modules](https://docs.python.org/3/py-modindex.html). Automated code tests that fail because of additional library imports will not recieve credit. Unless a problem instructs differently you may use any functions available from the Python stdlib and the libraries imported in the starter code.\n",
    "\n",
    "\n",
    "<details><summary><span style=\"color: blue; text-decoration: underline; cursor: pointer;\">Additional Details</span></summary>\n",
    "\n",
    "> **Do not delete, replace, or rearranged cells.** This erases `cell ids` upon which automated code tests are based. The \"Edit > Undo Delete Cells\" option in the notebook editor might be helpful; otherwise, redownload the notebook (so it has the correct required `cells ids`) and repopulate it with your answers (assuming you don't overwrite them when you redownload the notebook). ***You may add cells for scratch work*** but if required answers are not submitted through the provided cells where the answers are requested your answers may not be marked. Due to potential problems with `cell ids` **the only environments supported in this class are** [UofT JupyterHub](https://datatools.utoronto.ca/) or [Google Colab](https://colab.research.google.com/)\n",
    ">\n",
    "> **No jupyter shortcut commands** such as `! python script.py 10` or `%%timeit` may be included in the final submission as they will cause subsequent automated code tests to fail.\n",
    ">\n",
    "> **No cells may have any runtime errors** because this causes subsequent automated code tests to fail and you will not get marks for tests which fail because of previous runtime errors. ***Restart and re-run the cells in your notebook to ensure there are no runtime errors before submitting your work.***\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009d48a",
   "metadata": {},
   "source": [
    "## Student and Contribution\n",
    "\n",
    "Are you working with a partner to complete this assignment?  \n",
    "- If not, assign  the value of `None` into the variable `Partner`.\n",
    "- If so, assign the name of the person you worked with into the variable `Partner`.\n",
    "    - Format the name as `\"<First Name> <Last Name>\"` as a `str` type, e.g., \"Scott Schwartz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e558c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Partner = #None\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b75ad",
   "metadata": {},
   "source": [
    "What was your contribution in completing the code for this assignments problems?  \n",
    "Assign one of the following into each of the `Contribution` variable below.\n",
    "\n",
    "- `\"I worked alone\"`\n",
    "- `\"I contributed more than my partner\"`\n",
    "- `\"My partner and I contributed equally\"`\n",
    "- `\"I contributed less than my partner\"`\n",
    "- `\"I did not contribute\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Contribution = #\"I worked alone\"\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may use any functions available from the following library imports\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b7c21",
   "metadata": {},
   "source": [
    "## Part 1 (2.0 points): Speed\n",
    "\n",
    "There are two factors driving the computational speed of any algorithm:\n",
    "\n",
    "1. How many such operations are required to complete the algorithm for a given problem input size?\n",
    "2. How much time does each actual operation  in the algorithm (including accessing and managing memory) take?\n",
    "\n",
    "And since computers are fast what really becomes interesting here is:\n",
    "\n",
    "3. How does the required operation count scale as the problem size grows?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9032063",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "x_np_array = stats.norm().rvs(n)\n",
    "x_list = list(x_np_array)  # python lists are not \"linked list\" they are \"random access memory\" which means\n",
    "                           # they are an array of memory addresses all accessible at the same speed\n",
    "                           # https://stackoverflow.com/questions/3917574/how-is-pythons-list-implemented\n",
    "                           # ...but this doesn't mean they are \"vectorized\" like np.array's..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 100\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    sum(x_list)/n\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 1000\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    (x_np_array/n).sum()\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    (x_np_array).mean()\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1750290",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    (x_np_array).sum()/n\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ffc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_sum(x, return_cumulative_sequence=False):\n",
    "        \n",
    "    cumulative_sum = list(x)\n",
    "    for i,xi in enumerate(x[1:]):\n",
    "        cumulative_sum[i+1] = cumulative_sum[i]+x[i+1]\n",
    "        \n",
    "    if return_cumulative_sequence:\n",
    "        return cumulative_sum\n",
    "    return cumulative_sum[-1]\n",
    "    \n",
    "    \n",
    "def fan1(x):\n",
    "    \n",
    "    if len(x) <= 3:\n",
    "        return sum(x)\n",
    "    try: \n",
    "        return fan1(list(np.array(x[0::2])+np.array(x[1::2])))\n",
    "    except:\n",
    "        return fan1(list(np.array(x[0::2])+np.array(x[1::2]+[0])))\n",
    "\n",
    "\n",
    "def fan2(x):\n",
    "    \n",
    "    if len(x) <= 3:\n",
    "        return sum(x)\n",
    "    return fan2(x[:int(len(x)/2)]) + fan2(x[int(len(x)/2):])\n",
    "        \n",
    "    \n",
    "def kahan(x, return_cumulative_sequence=False):   \n",
    "    \n",
    "    cumulative_sum = list(x)\n",
    "    detectable_lost_error = list(x)\n",
    "    s,e = x[0],0\n",
    "    for i,xi in enumerate(x[1:]):\n",
    "        x_ = xi - e\n",
    "        detectable_lost_error[i] = e - (xi - x_)\n",
    "        s_ = s + x_\n",
    "        e = (s_ - s) - x_\n",
    "        s = s_      \n",
    "        cumulative_sum[i+1] = s\n",
    "    if return_cumulative_sequence:            \n",
    "        return cumulative_sum#,detectable_lost_error\n",
    "    return cumulative_sum[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230896a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1q1 = \"<`sum(x_list)/n`|`(x_np_array/n).sum()`|`(x_np_array).mean()`|`(x_np_array).sum()/n`> is \"+\\\n",
    "       \"the intermediate performing operation because it <avoids|too often|only once> divides by n\"\n",
    "\n",
    "p1q2 = 'The approximate number of times the `\"fan\"` methods will recursively '+\\\n",
    "        '\"divide and conquer\" to complete the summation of the data is <A|B|C|D>'\n",
    "# A: np.log(len(x))\n",
    "# B: np.log2(len(x))\n",
    "# C: np.log10(len(x))\n",
    "# D: np.sqrt(len(x))\n",
    "\n",
    "p1q3 = 'The approximate number of addition operations the `\"fan\"` methods '+\\\n",
    "        'use in order to complete the summation of the data is <A|B|C|D>'\n",
    "# A: len(x)\n",
    "# B: np.log2(len(x))\n",
    "# C: np.log10(len(x))\n",
    "# D: np.sqrt(len(x))\n",
    "\n",
    "p1q4 = 'The approximate amount of `list` space the `\"fan1\"` method must '+\\\n",
    "       \"store on its function stack to complete its summation of the data \"+\\\n",
    "       'assuming each `\"fan1\"` call stores its input on the stack is <A|B|C|D>'\n",
    "# A: len(x)\n",
    "# B: 2*len(x)\n",
    "# C: len(x)**2\n",
    "# D: np.log2(len(x))*len(x)\n",
    "\n",
    "p1q5 = 'The approximate amount of `list` space the `\"fan2\"` method must '+\\\n",
    "       \"store on its function stack to complete its summation of the data \"+\\\n",
    "       'assuming each `\"fan2\"` call stores its input on the stack is <A|B|C|D>'\n",
    "# A: len(x)\n",
    "# B: 2*len(x)\n",
    "# C: len(x)**2\n",
    "# D: np.log2(len(x))*len(x)\n",
    "\n",
    "p1q6 = \"The algorithm that offers the potential to intentionally code \"+\\\n",
    "       'some vectorization is the <`\"sorted_sum\"`|`\"fan1\"`|`\"fan2\"`|`\"kahan\"`> method'\n",
    "\n",
    "p1q7 = \"The fasted to slowest of our summation functions is \"+\\\n",
    "       \"np.sum -> sorted_sum -> fan1 -> fan2 -> kahan\"  # reorder in this given format\n",
    "\n",
    "p1q8 = \"The above results correspond to \"+\\\n",
    "       \"vectorization -> no vectorization -> recursive overhead -> storage overhead -> operation count\"\n",
    "       # reorder in this given format corresponding to the previous answer\n",
    "\n",
    "p1q9 = \"The algorithms whose computational costs would be expected to scale linearly \"+\\\n",
    "       'with the size of the input are <`\"np.sum\"`|`\"sorted_sum\"`|`\"fan1\"`|`\"fan2\"`|`\"kahan\"`>'\n",
    "       # keep the order as is and separate the algorithms not removed by a space (removing all <|> symbols)\n",
    "\n",
    "p1q10 = \"Order the algorithms whose computational costs would not be expected to scale quite linearly \"+\\\n",
    "        'from worst to best scaling computational costs <`\"np.sum\"`|`\"sorted_sum\"`|`\"fan1\"`|`\"fan2\"`|`\"kahan\"`>'\n",
    "        # order the algorithms not removed worst to best by \" -> \" as usual (removing all <|> symbols)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d29765",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000000\n",
    "x_np_array = stats.norm().rvs(n)\n",
    "x_list = list(x_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a19b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "x_np_array.sum()\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "sorted_sum(x_list)\n",
    "tic = time.time()\n",
    "tic-toc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "fan1(x_list)\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "fan2(x_list)\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abdee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "kahan(x_list)\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add cells into your notebook but\n",
    "# just don't runtime errors anywhere in your notebook\n",
    "# as cells are run sequentially for automated testing\n",
    "\n",
    "# Automated testing is looking for cells (`cell ids`)\n",
    "# where you're asked to enter answers or complete code \n",
    "# but all other cells like this one or cells you add\n",
    "# are safe to delete if you want a \"cleaner\" notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bd030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss_two_pass():\n",
    "    xbar = x[0]/n\n",
    "    for i in range(1, n):\n",
    "        xbar = xbar + x[i]/n\n",
    "    sse = 0\n",
    "    for i in range(0, n):\n",
    "        sse = sse + (x[i]-xbar)**2\n",
    "    return sse/n\n",
    "\n",
    "def ss_two_pass_only_operations():\n",
    "    xi = x[0]\n",
    "    xbar = xi/n\n",
    "    for i in range(1, n):\n",
    "        xbar = xbar + xi/n\n",
    "    sse = 0\n",
    "    for i in range(0, n):\n",
    "        sse = sse + (xi-xbar)**2\n",
    "    return sse/n\n",
    "\n",
    "def ss_one_pass():\n",
    "    sumx = x[0]\n",
    "    sumx2 = sumx**2\n",
    "    for i in range(1, n):\n",
    "        xi = x[i]\n",
    "        sumx = sumx+xi\n",
    "        sumx2 = sumx2+xi**2\n",
    "    return sumx2-(sumx**2)/n\n",
    "\n",
    "def ss_one_pass_only_operations():\n",
    "    xi = x[0]\n",
    "    sumx = xi\n",
    "    sumx2 = sumx**2\n",
    "    for i in range(1, n):\n",
    "        sumx = sumx+xi\n",
    "        sumx2 = sumx2+xi**2\n",
    "    return sumx2-(sumx**2)/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83345829",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "x = stats.norm().rvs(n)\n",
    "\n",
    "trials = 1000\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "\n",
    "    ss_two_pass()\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "ss_two_pass_time = timesum/trials\n",
    "ss_two_pass_time\n",
    "\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    ss_one_pass()\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "ss_one_pass_time = timesum/trials\n",
    "ss_one_pass_time\n",
    "\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    ss_two_pass_only_operations()\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "ss_two_pass_only_operations_time = timesum/trials\n",
    "ss_two_pass_only_operations_time\n",
    "\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    ss_one_pass_only_operations()\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "ss_one_pass_only_operations_time = timesum/trials\n",
    "ss_one_pass_only_operations_time\n",
    "\n",
    "(ss_two_pass_time-ss_two_pass_only_operations_time)/(ss_one_pass_time-ss_one_pass_only_operations_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1q11 = \"The final code demonstration of summation algorithms shows the benefits of \"+\\\n",
    "        \"<online|realtime> over <online|realtime> algorithms\"\n",
    "\n",
    "p1q12 = \"This demonstration shows the benefit to be a factor of around X (as expected)\"\n",
    "        # replace X with an integer\n",
    "\n",
    "p1q13 = \"And this is a function of the cost of <memory access|numerical operations>\"\n",
    "\n",
    "p1q14 = 'According to the information below, the <`\"np.sum\"`|`\"sorted_sum\"`|`\"kahan\"`> algorithm '+\\\n",
    "        'offers a \"middle ground\" accuracy-computation tradeoff'\n",
    "\n",
    "p1q15 = \"According to the information below, the added computational cost incurred \"+\\\n",
    "        \"from sorting in the <is|is not> justified\"\n",
    "\n",
    "p1q16 = 'The \"fan\" algorithm tends to keep terms to be added on similar scales as a side-effect of a '+\\\n",
    "        '<\"divide and conquer\"|sequential error managment> algorithm'\n",
    "\n",
    "p1q17 = \"Kahan's algorithm <is|is not> necessary to achieve maximal computational numerical accuracy\"\n",
    "\n",
    "p1q18 = 'The <np.sum|`\"fan1\"`|`\"fan2\"`> algorithm best demonstrates the meaning of \"divide and conquer\" '+\\\n",
    "        'which <must|need not> be implemented using recursion'\n",
    "\n",
    "p1q19 = \"The information below demonstrates a computational <time VS accuracy|time VS space> tradeoff\"\n",
    "\n",
    "p1q20 = \"The `ss_one_pass` and `ss_two_pass` functions above demonstrate \"+\\\n",
    "        \"the computational <time VS space tradeoff|cost of using memory>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9314d9",
   "metadata": {},
   "source": [
    "### Speed yes, but what of accuracy?\n",
    "\n",
    "For some positive scalar constants $a \\approx c \\approx d$ and $b>1$ that do not change as $n$ grows large\n",
    "\n",
    "$\n",
    "\\begin{array}{r|ll}\n",
    "& \\textrm{roundoff error} & \\textrm{number of numeric operations} \\\\\\hline\n",
    "\\textrm{sequential summation} & f(n) = a\\times \\epsilon_{\\textrm{machine}}n & n-1\\\\\n",
    "\\textrm{sorted sequential summation} & f(m) \\textrm{ for } n/2 < m < n & n-1+b\\times n\\log(n) \\textrm{ operations for sorting}\\\\\n",
    "& \\textrm{so maybe factor of 2} & \\textrm{for good well known sorting algorithms}\\\\\n",
    "& \\textrm{so error accumulates} & \\textrm{unavoidably for large cumulative sums}\\\\\\hline\n",
    "\\textrm{\"fan\" pairwise summation} & c\\times \\epsilon_{\\text{machine}} \\log n & n-1\\\\\n",
    "\\textrm{Kahan's method} & d \\times \\epsilon_{\\text{machine}} & 4n\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bfc1df",
   "metadata": {},
   "source": [
    "## Part 2: Solving `Ax=b` and \"least squares\"\n",
    "\n",
    "As described in the optional linear algebra material, **Gaussian elimination** re-expresses a **system of linear equations** $Ax=b$ in **row eschelon form**. For an **invertible matrix** $A$ and identity matrix $I$, there exists an **upper triangular matrix** $U$ and **upper triangular matrix** $L$ such that  \n",
    "\n",
    "$$[A|I|b] \\quad \\underset{\\textrm{Elimination}}{\\overset{\\textrm{Gaussian}}{\\longrightarrow}} \\quad [U|L^{-1}|b']\n",
    "={} L^{-1} \\times [A=LU|I|b]  \\quad \\underset{\\textrm{Substitution}}{\\overset{\\textrm{Backward}}{\\longrightarrow}} \\quad L^{-1}A = Ux = b' = L^{-1}b$$\n",
    "\n",
    "allowing $x$ to be solved for by **backward substitution** based on **upper triangular matrix** $U$.\n",
    "\n",
    "> The statement above is simplified and may require a **permutation matrix** $P$\n",
    "> ```Python\n",
    "> # L and U in both factorizations below are identical but\n",
    "> P,L,U = linalg.lu(np.array([[1,1],[0,1]]))  # P is the identity matrix\n",
    "> P,L,U = linalg.lu(np.array([[0,1],[1,1]]))  # `np.ones((2,2))-P` is the identity matrix\n",
    "> ```\n",
    "\n",
    "It can be shown that \n",
    "\n",
    "- the number of divisions and multiplication-additions that **Gaussian elimination** requires to create the **upper triangular matrix** $U$ and $b'$ by manipulating $[A|b] \\rightarrow [U|b']$ is\n",
    "  $$\\sum_{j=1}^n (j+1)(j-1) + (j-1) = \\sum_{j=1}^n j^2 - 1 + (j-1) = \\frac{n(n+1)(2n+1)}{6} - n + \\frac{n(n+1)}{2} - n = \\mathcal{O}(n^3)$$\n",
    "- while the number of arithmetic operations required to complete the **backward substitution** is\n",
    "  $$\\sum_{j=n}^1 1 + 2(n-j) = \\sum_{j=0}^{n-1} (1 + 2j) = n + 2 \\sum_{j=0}^{n-1} j = n + 2\\frac{n(n-1)}{2} = n^2 = \\mathcal{O}(n^2)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "A, b = stats.norm.rvs(size=(n,n)), stats.norm.rvs(size=(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `np.linalg.solve` solves for `x` by performing\n",
    "# Gaussian Elimination followed by Backward Substitution \n",
    "trials = 50\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    np.linalg.solve(A, b)\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this solving process may be vectorized to solve m equations \n",
    "m = n  # just for demonstration purposes\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    np.linalg.solve(A, np.array([b[:,0]]*m))\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not vectorized and so it's 3 times slower as a result\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    for i in range(3):\n",
    "        np.linalg.solve(A, b)\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    scipy.linalg.solve(A, b)\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962dd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2q1 = 'In the demonstration of summations in the previous \"Part A\" '+\\\n",
    "       \"the most powerful tool to increase computational speed was \"+\\\n",
    "       \"<recursion|vectorization|divide and conquer algorithms|realtime algorithms> which\"+\\\n",
    "       '<again appears|no longer appears> useful in the current context of \"Part B\"'\n",
    "\n",
    "p2q2 = \"The scipy and numpy computational speeds demonstrated above differ due to \"+\\\n",
    "       \"<random runtime variation|them implementing different algorithms>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb904d4",
   "metadata": {},
   "source": [
    "Conceptually, $A^{-1}$ (and $x$) may be found by a continuation of the **Gaussian elimination** process\n",
    "\n",
    "$[A|I|b] \\quad \\underset{\\textrm{Elimination}}{\\overset{\\textrm{Gaussian}}{\\longrightarrow}} \\quad [U|L^{-1}|b']\n",
    "={} L^{-1} [A=LU|I|b]  \\quad \\underset{\\textrm{Swimming}}{\\overset{\\textrm{Just Keep}}{\\longrightarrow}} \\quad [I|U^{-1}L^{-1}|x]\n",
    "={} U^{-1}L^{-1} [A=LU|I|b=Ax]$\n",
    "\n",
    "but because **Gaussian elimination** is an $\\mathcal{O}(n^3)$ process (as seen above) what is instead done is a vectorized version of solving for each column of the $A^{-1}$ using $n$ rounds of **backward substitution**\n",
    "\n",
    "$\\begin{align}\n",
    "AA^{-1}_{\\cdot c} =  I_{\\cdot c} &\\Longrightarrow{} L^{-1}\\times AA^{-1}_{\\cdot c} \n",
    "= L^{-1}\\times I_{\\cdot c}\\\\\n",
    "&\\Longrightarrow{} UA^{-1}_{\\cdot c} \n",
    "= L^{-1}_{\\cdot c}\n",
    "\\end{align}$\n",
    "\n",
    "The $n$ rounds of the $\\mathcal{O}(n^2)$ process of **backward substitution** is an $\\mathcal{O}(n^3)$ process, but through vectorization the $n$ rounds of  $\\mathcal{O}(n^3)$ process can be done in parallel, leaving us with what is effectively an $\\mathcal{O}(n^2)$ process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7445169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `np.linalg.inv(A)` creates the LU decomposition and then solves for each column of A^{-1}\n",
    "# by repeadedly using backward substitution L^{-1}(A)[A^{1}][:,c] = L^{-1}[I][:,c]\n",
    "# in a vectorized manner\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    np.linalg.inv(A) @ b\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ee6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the \"vectorized manner\" is something like the following\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    LU = scipy.linalg.lu_factor(A)\n",
    "    scipy.linalg.lu_solve(LU, np.eye(n))\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n",
    "# which is a runtime that reflects very similar vectorization \n",
    "# costs as would be seen for np.linalg.solve(A, b*np.eye(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not vectorized and so it's about 3 times slower as a result\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    #LU = scipy.linalg.lu_factor(A)\n",
    "    P,L,U = scipy.linalg.lu(A)  # alternative version\n",
    "    # scipy.linalg.lu_factor?\n",
    "    # but ignoring `piv` indices\n",
    "    for c in range(3):\n",
    "        # doesn't just do backward substitution but also does Gaussian elimination because\n",
    "        #np.linalg.solve(np.triu(LU[0]), np.tril(LU[0])[:,c])  # it can't assume triangular\n",
    "        #scipy.linalg.solve(np.triu(LU[0]), np.tril(LU[0])[:,c], assume_a='sym', lower=False)\n",
    "        scipy.linalg.solve(U, L[:,c], assume_a='sym', lower=False)  # alternative version\n",
    "        \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d09289",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    scipy.linalg.inv(A) @ b\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8df5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2q3 = \"Computational speed for `np.linalg.inv(A) @ b` versus `np.linalg.solve(A, b)` \"+\\\n",
    "       \"as demonstrated here have a relative factor of about <1|2-3|n>\"\n",
    "p2q4 = \"Without vectorization the computational speed for `np.linalg.inv(A) @ b` versus \"+\\\n",
    "       \"`np.linalg.solve(A, b*np.eye(n))`would have a relative factor of around <1|2-3|n>\"\n",
    "p2q5 = \"The essential algorithm for matrix inversion is <A|B|C|D> which makes it \"+\\\n",
    "       \"<essentially the same as|very different from> `np.linalg.solve(A,np.eye(n))`\"\n",
    "# A: Just a lot of (vectorized) backward substitution\n",
    "# B: Gaussian elimination followed by backward substitution \n",
    "# C: Gaussian elimination followed by a lot of (vectorized) backward substitution\n",
    "# D: Gaussian elimination followed by the same amount of Gaussian elimination again\n",
    "\n",
    "p2q6 = \"The analogous scipy and numpy computational speeds directly compared above differ due to \"+\\\n",
    "       \"<random runtime variation|them implementing different algorithms>\"\n",
    "\n",
    "p2q7 = 'The \"least squares\" estimate should be solved for as '+\\\n",
    "       \"<`np.linalg.solve(X.T@X,X.T@y)`|`np.linalg.inv(X.T@X)@(X.T@y))`>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67856a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add cells into your notebook but\n",
    "# just don't runtime errors anywhere in your notebook\n",
    "# as cells are run sequentially for automated testing\n",
    "\n",
    "# Automated testing is looking for cells (`cell ids`)\n",
    "# where you're asked to enter answers or complete code \n",
    "# but all other cells like this one or cells you add\n",
    "# are safe to delete if you want a \"cleaner\" notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a05a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892698b7",
   "metadata": {},
   "source": [
    "## So what does this have to do with \"least squares\" $\\min \\sum_i \\hat e_i^2$?\n",
    "\n",
    "$\\huge\\quad\\quad\\quad\\;\\;\\; X\\hat \\beta \\approx y \\quad \\textrm{ looks like } \\quad Ax = b$  \n",
    "\n",
    "$\\huge\\textrm{but } \\quad X^T X\\hat \\beta = X^Ty \\quad \\textrm{ is } \\quad Ax = b$  \n",
    "\n",
    "---\n",
    "\n",
    "$\n",
    "\\Large\n",
    "\\begin{align}\n",
    "\\hat \\beta = \\underset{\\beta}{\\textrm{argmin}} \\overset{\\textrm{squared $L_2$ norm}}{||\\underbrace{y - X\\beta}_{\\epsilon} ||^2_2} \n",
    "&={} \\underset{\\beta}{\\textrm{argmin}}\\quad \\sqrt{(y - X\\beta)^T(y - X\\beta )}\\\\\n",
    "&={} \\underset{\\beta}{\\textrm{argmin}}\\quad {(y - X\\beta)^T(y - X\\beta)}\\\\\n",
    "&={} \\underset{\\beta}{\\textrm{argmin}}\\quad X\\beta^TX^T\\beta - 2\\beta^TX^Ty \\\\\n",
    " \\Longrightarrow 0 &={} \\nabla_\\beta \\left( \\beta^TX^TX \\beta -2\\beta^TX^Ty \\right)\\\\\n",
    "  0 = {} &  X^TX \\hat \\beta - X^T y  \\quad\\quad \\color{gray}{\\Longrightarrow \\quad  \\underset{{\\text{$\\sum_i \\hat \\epsilon_i = 0$ if $X$ has an intercept column} }}{\\overset{\\text{residuals are othogonal to the columns of $X$}}{0 = X^T (X \\hat \\beta - y) = X^T\\hat \\epsilon }}} \\\\\n",
    "   \\Longrightarrow \\quad  X^TX \\hat \\beta = {} & X^T y \\quad \\longleftarrow \\quad \\textrm{the so-called } \\textit{normal equations}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "### $\\hat \\beta$ is the solution to the **normal equations** $\\require{cancel}\\xcancel{Ax = b}$ $X^TX \\hat \\beta =  X^T y$ and thus the familiar analytical solution  $\\require{cancel}\\xcancel{x = A^{-1}b}$  $\\hat \\beta = (X^TX)^{-1} X^T y$ is the \"least squares\" estimate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2584d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2q8 = 'The \"least squares\" estimate should be solved for as '+\\\n",
    "       \"<`np.linalg.solve(X.T@X,X.T@y)`|`np.linalg.inv(X.T@X)@(X.T@y))`>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6b386",
   "metadata": {},
   "source": [
    "## Part 3: other ways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19ba13",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "The **Moore-Penrose (generalized) inverse** of $X^TX$ based on the SVD $X = UDV^T$ is \n",
    "\n",
    "$(X^TX)^+ = (VD^{-2}V^T)$ since $(X^TX)(X^TX)^+ = (X^TX)^+(X^TX) = I$\n",
    "\n",
    "$\\begin{align}\n",
    "X = UDV^T && X^TX(VD^{-2}V^T) &={} (UDV^T)^T(UDV^T)(VD^{-2}V^T) = (VD^2V^T)(VD^{-2}V^T) = \\overset{\\textrm{orthonormality}}{VV^T = I}\\\\\n",
    "&& (VD^{-2}V^T)X^TX &={} (VD^{-2}V^T)(UDV^T)^T(UDV^T) = (VD^{-2}V^T)(VD^2V^T) = \\overset{\\textrm{orthonormality}}{V^TV = I}\\\\\\\\\n",
    "&& X^TX \\hat \\beta &={} (VD^{-2}V^T) X^T y\\\\\n",
    "&& (X^TX)^+X^TX \\hat \\beta &={} (X^TX)^+X^T y\\\\\n",
    "&&  \\hat \\beta &={} (VD^{-2}V^T) (UDV^T)^T y\\\\\n",
    "&&  &={} VD^{-1}U^T y\\\\\n",
    "\\end{align}$\n",
    "\n",
    "### SVD redux \n",
    "\n",
    "Diagonal $D$ from compact SVD is invertible with $D^{-1}_{ii} = 1/D_{ii}$, and $U$ and $V$ are orthogonormal so $U^TU=U^{-1}U=I$ and $V^TV=V^{-1}V=I$\n",
    "\n",
    "$\\require{cancel}\n",
    "\\begin{align}\n",
    "&& X^TX \\hat \\beta &={} X^T y\\\\\n",
    "X = UDV^T && VD^2V^T \\hat \\beta &={}  VDU^T y\\\\\n",
    " && \\cancel{(VD^{-2}V^T)VD^2V^T} \\hat \\beta &={}  (VD^{-2}V^T)VDU^T y\\\\\n",
    " && &={} VD^{-1}U^T y\n",
    "\\end{align}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97e628",
   "metadata": {},
   "source": [
    "### The Cholesky\n",
    "\n",
    "All **symmetric** $\\Sigma = \\Sigma^T$ and **positive definite** $x^T\\Sigma x > 0$ have a **Cholesky decomposition** \n",
    "\n",
    "$$\\Sigma = CC^T \\quad \\text{with lower triangular }C \\text{ (which is unique when $C_{ii} >0$)}$$\n",
    "\n",
    "If $X$ is **full rank** then $(X^TX)$ is **symmetric full rank** and it has all **positive eigenvalues** so it's **positive definite** with $z^TX^TXz > 0$ for all $z$.\n",
    "\n",
    "$\\begin{align*}\n",
    "&& X^T\\!X\\hat \\beta &={} X^T\\!y \\\\\n",
    "\\Longrightarrow && CC^T \\hat \\beta &={} X^T\\!y \\\\\n",
    "&& \\color{gray}{C(C^T \\hat \\beta)} &={} \\color{gray}{X^T\\!y}\\\\\n",
    "\\Longrightarrow && C \\gamma &={} X^T\\!y && \\longleftarrow C \\textrm{ is lower triangular}\\\\\n",
    "\\Longrightarrow && C^T \\hat \\beta &={} \\gamma && \\longleftarrow C^T \\textrm{ is upper triangular}\n",
    "\\end{align*}$\n",
    "\n",
    "which is solved for $\\hat \\beta$ in two passes of **backward substitution**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df2dbc",
   "metadata": {},
   "source": [
    "### QR decomposition\n",
    "\n",
    "A **full rank** $X$ may be factored into $X=QR$ the product of a ($Q^TQ=I$) **semi-orthonormal** $Q$ times an **upper triangular matrix** $R$.\n",
    "\n",
    "\n",
    "$\\begin{align}\n",
    "&& X \\hat \\beta & \\approx y & X^TX \\hat \\beta &={} X^T y \\\\\n",
    "X=QR && QR \\hat \\beta & \\approx {} y  & R^TR \\hat \\beta &={} (QR)^T y \\quad \\longleftarrow \\quad (R^T)^{-1}=R^{-T} \\textrm{ exists since $R$ is full rank if $X$ is} \\\\\n",
    " && R \\hat \\beta & \\overset{?}{=} {} Q^Ty  &  \\overset{\\textrm{yes}}{\\longrightarrow} \\quad\\quad R \\hat \\beta &={} Q^T y   \\quad\\quad\\; \\longleftarrow \\quad R \\textrm{ is upper triangular} \n",
    " \\end{align}$\n",
    "\n",
    "so this is solved for $\\hat \\beta$ in one pass of **backward substitution**.\n",
    "\n",
    "It is [common advice](https://www.quora.com/Is-it-better-to-do-QR-Cholesky-or-SVD-for-solving-least-squares-estimate-and-why) to solve for $\\hat \\beta$ via **QR decomposition** of $X$ rather than computing $X^TX$.\n",
    "\n",
    "> A **(modified) Gram-Schmidt procedure** can sequentially **orthonormalize** the columns of $X$ to form $Q$. Since this is based on subtracting all non-orthogonal components of the previous columns as $X_{\\cdot j} = X_{\\cdot j} - (X_{\\cdot j}^TX_{\\cdot j'})X_{\\cdot j'}$ so that $X_{\\cdot j'}^TX_{\\cdot j} = X_{\\cdot j'}^T(X_{\\cdot j} - (X_{\\cdot j}^TX_{\\cdot j'})X_{\\cdot j'})=0$, the reverse of the process is a weighted sum of each column with all the previous columns. Thus $R$ in $X=QR$ will indeed be an **upper triangular matrix**.\n",
    ">\n",
    "> - $Q$ can be more robustly computer using **Householder transformations** or **Givens transformations** (each respectively also known as **reflections** and **rotations**), and the latter are especially efficient if the data arives from memory row by row.\n",
    ">\n",
    "> The **QR decomposition** is **rank revealing** when $X$ is not **full rank** since **linearly dependent** columns produce $\\mathbf{0}$ column vectors\n",
    ">\n",
    "> $$\\overset{\\text{rank } r}{X_{n\\times m}} = \n",
    "\\overset{\\text{orthonormal}}{\\left[\\overbrace{Q_{n\\times r}}^{\\text{semi-}} \\; \\Big | \\; \\mathbf{0}_{n\\times (n-r)}\\right]}_{n \\times n} \\overset{\\text{trapezoidal}}{\\left[\\begin{array}{c}R_{r\\times m}\\\\\\mathbf{0}\\end{array} \\right]}_{n \\times m} = \\;\\;\\;Q_{n\\times r}R_{r\\times m}$$\n",
    "\n",
    "\n",
    "<!--\n",
    "\n",
    "Column $j$ of $Q$ is a linear combination of the first $j$ columns of $X$ so for some ***upper trapezoidal matrix*** $R$\n",
    "\n",
    "$$X = QR \\quad \\text{ with }\\textbf{(semi-)orthonormal } {Q_{\\cdot j}^TQ_{\\cdot j'} = \\left\\{\\begin{array}{l}1: \\text{if } j=j' \\quad  \\text{i.e., the columns are normal vectors}\\\\0: \\text{if } j\\not=j'  \\quad \\text{i.e., the columns are orthogonal}\\end{array}\\right.}$$\n",
    "\n",
    "***QR Decomposition*** can also speed up solving ($n>m$) ***overdetermined*** (but ***consistent***) $A_{n \\times m}x=b$ (as opposed to $Ax\\approx b$) whenever $\\text{rank}(A) =r << m$ since \n",
    "\n",
    "$$A_{n \\times m}x = \\left[Q_{n \\times r}|Q_{n \\times (m-r)}'\\right] \\left[\\begin{array}{c}R_{r\\times m}\\\\\\mathbf{0}\\end{array} \\right] x=b \\quad \\text{ so } \\quad \\left[\\begin{array}{c}R\\\\\\mathbf{0}\\end{array} \\right]x = \\left[\\begin{array}{c}Q^T\\\\ Q'^T\\end{array} \\right] b$$\n",
    "\n",
    "and (when $A_{n \\times m}x=b$ is indeed ***consistent***)\n",
    "\n",
    "$$R_{r\\times r} \\overbrace{\\left[\\begin{array}{c}\\tilde x_{r\\times 1}\\\\\\mathbf{0}\\end{array} \\right]}^{x} =  \\overbrace{\\left[\\begin{array}{c} Q^T_{r \\times n} b_{n\\times 1}\\\\\\mathbf{0}\\end{array} \\right]}^{Q^Tb} \\quad \\text{ so } \\quad R_{r \\times r} \\tilde x = Q^Tb$$\n",
    "\n",
    "and this is a very small ***backward substitution*** compared to $L_{n \\times n}^{-1} A_{n \\times m}x = U_{n \\times m}x = L_{n \\times n}^{-1}b$.\n",
    "\n",
    "So even though $O(n^2m)$ ***QR decomposition*** will be about 5 times slower than ***Gaussian*** elimination (as seen above), this disadvantage may be made up for during the ***backward substitution*** step where $O(r^2)$ can be substantially faster than $O(nm)$.  And, actually, the general solution to an ***overdetermined*** system is to use the ***pseudoinverse*** available from ***SVD***. \n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2q9 = 'The \"least squares\" estimate should be solved for using <A|B|C|D|E>'\n",
    "# A: np.linalg.solve(X.T.dot(X),X.T.dot(y))\n",
    "# B: A SVD\n",
    "# C: Cholesky decomposition \n",
    "# D: QR decomposition \n",
    "# E: ... Um, well, I guess it's going to depend on the speed and accuracy of these algorithms!!\n",
    "# But regardless definitely https://www.youtube.com/shorts/wdIOC-uwgWU\n",
    "# as far as when it comes to `np.linalg.inv(X.T.dot(X))@(X.T.dot(y))`\n",
    "\n",
    "# For the following questions suppose the following dimensions and objects\n",
    "n,p = 100,10\n",
    "X,y = stats.norm.rvs(size=(n,p)), stats.norm.rvs(size=(n,1))\n",
    "\n",
    "# Text string of code to output beta-hat from `X` using SVD with names as `X` = `(U[:,:p]*s)@Vt` \n",
    "# which equals `U[:,:p]@np.diag(s)@Vt` but `np.diag(s)` is unnecessary so only use `*` or `/` to\n",
    "# express your beta-hat computation and put multiple lines of code on one line separated by `;`\n",
    "p2q10 = \"\"  # this takes two lines of code (but put there here as one line spearated by `;`)\n",
    "# Either numpy or scipy is fine but don't use `.dot()` or `np.diag(s)`\n",
    "# Rather than using `[:,:p]` feel free to pass `full_matrices=False` to your function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1cad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add cells into your notebook but\n",
    "# just don't runtime errors anywhere in your notebook\n",
    "# as cells are run sequentially for automated testing\n",
    "\n",
    "# Automated testing is looking for cells (`cell ids`)\n",
    "# where you're asked to enter answers or complete code \n",
    "# but all other cells like this one or cells you add\n",
    "# are safe to delete if you want a \"cleaner\" notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91780d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f1e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text string of code to output beta-hat from `X` using the Cholesky decomposition\n",
    "# with names as `X` = `L@L.T` and the multiple lines of code put on one line separated by `; `\n",
    "p2q11 = \"\"  # this takes three lines of code (but put there here as one line spearated by `;`)\n",
    "# First use the numpy implementation since if you use scipy you'll need to add `lower=True`\n",
    "# But then use the scipy implementation first with `assume_a='sym', lower=True` \n",
    "# and naming result `gamma` and then use `assume_a='sym', lower=False` so only backward substitution \n",
    "# is performed (as the numpy implementation will unnecessarily do Gaussian elimintion) \n",
    "# and don't use `.dot()`\n",
    "\n",
    "# Text string of code to output beta-hat for `X` using the QR decomposition\n",
    "# with names as `X` = `Q[:p,:p]@R[:,:p]` and the multiple lines of code put on one line separated by `; `\n",
    "p2q12 = \"\"  # this takes two lines of code (but put there here as one line spearated by `;`)\n",
    "\n",
    "# time your algorithms using the code structure below and sort them from fastest to slowest\n",
    "\n",
    "np.random.seed(410)\n",
    "n,p = 10000,1000\n",
    "X,y = stats.norm.rvs(size=(n,p)), stats.norm.rvs(size=(n,1))\n",
    "\n",
    "# for the set up above, n,p = 10000,1000... from fastest to slowest\n",
    "p2q13 = \"(X.T@X,X.T@y) --> np.linalg.inv --> np.linalg.solve --> SVD --> np.linalg.lstsq --> Cholesky --> QR\"\n",
    "        # correctly reorder while keeping the provided formatting the same\n",
    "\n",
    "p2q14 = \"The most expensive computation is <(X.T@X,X.T@y)|np.linalg.inv|np.linalg.solve> \"+\\\n",
    "        \"<and fortunately it can|but unfortunately it cannot> be avoided\"\n",
    "\n",
    "p2q15 = \"Cholesky Decomposition --> QR Decomposition --> Singular Value Decomposition\"\n",
    "        # correctly reorder while keeping the provided formatting the same\n",
    "\n",
    "p2q16 = \"The `np.linalg.lstsq` method is based on the SVD \"+\\\n",
    "        \"<but it must not fully implement all aspects of `np.linalg.svd`|and it therefore likely simply calls `np.linalg.svd`>\"\n",
    "        # correctly reorder while keeping the provided formatting the same\n",
    "\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.linalg.qr.html\n",
    "# mentions Gram-Schmidt (and Householder reflections, incidentally)\n",
    "p2q17 = 'The reference material above indicates that \"least squares\" computation '+\\\n",
    "        '\"in practice\" is most commonly completed using <A|B|C|D|E>'\n",
    "# A: np.linalg.inv\n",
    "# B: np.linalg.solve\n",
    "# C: np.linalg.lstsq (which is based on np.linalg.svd)\n",
    "# D: np.linalg.cholesky\n",
    "# E: np.linalg.qr\n",
    "\n",
    "# https://www.quora.com/Is-it-better-to-do-QR-Cholesky-or-SVD-for-solving-least-squares-estimate-and-why\n",
    "p2q18 = 'The commentary above indicates that \"least squares\" computation '+\\\n",
    "        '\"in practice\" is most commonly completed using <A|B|C|D|E> '+\\\n",
    "        \"while at the same time recommending <A|B|C|D|E>\"\n",
    "# A: np.linalg.inv\n",
    "# B: np.linalg.solve\n",
    "# C: np.linalg.lstsq (which is based on np.linalg.svd)\n",
    "# D: np.linalg.cholesky\n",
    "# E: np.linalg.qr\n",
    "\n",
    "p2q19 = \"Using `(XTX+XTX.T)/2` is particular advisable as an input for <A|B|C|D|E>\"\n",
    "# A: np.linalg.inv\n",
    "# B: np.linalg.solve\n",
    "# C: np.linalg.svd and np.linalg.lstsq\n",
    "# D: np.linalg.cholesky\n",
    "# E: np.linalg.qr\n",
    "\n",
    "# What is the condition number of the Ax=b \"least squares\" problem for `X` as given above?\n",
    "p2q20 = float  # give me all the decimal points provided by the functions you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02160cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(410)\n",
    "n,p = 10000,1000\n",
    "X,y = stats.norm.rvs(size=(n,p)), stats.norm.rvs(size=(n,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc7323",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 50\n",
    "timesum = 0\n",
    "XTX = X.T.dot(X)  # don't measure this computation for comparision, but of course it must be done!\n",
    "XTy = X.T.dot(y)  # don't measure this computation for comparision, but of course it must be done!\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    np.linalg.inv(XTX)@XTy\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 50\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    np.linalg.solve(XTX,XTy)\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940086d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 50\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    np.linalg.solve(X.T.dot(X),X.T.dot(y))  # now measure everythihng all of it together now\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "\n",
    "# Time just a single SVD for uisng the numpy version\n",
    "# but add `full_matrices=False`\n",
    "U,s,Vt = np.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "\n",
    "# Time just a single SVD for uisng the numpy version \n",
    "# but add `full_matrices=False`\n",
    "U,s,Vt = scipy.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 50\n",
    "timesum = 0\n",
    "# precompute the SVD outside of the timing measurement\n",
    "#U,s,Vt = None,None,None # don't measure this computation for comparision, but of course it must be done!\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    # Just the second part of the SVD solving code submited for `p2q10` after the the `;`\n",
    "    None\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ea414",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 10\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "\n",
    "    # Here are built-in SVD based least squares solving algorithms\n",
    "    # np.linalg.lstsq(X, y, rcond=None) \n",
    "    scipy.linalg.lstsq(X, y) \n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a162db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 10\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    # All three lines of code submitted for `p2q11` separated by `;`\n",
    "    # solving for beta-hat using the Cholesky decomposition\n",
    "    None\n",
    "    # And note that this includes ALL computations including X.T@X, the Cholesky, and X.T@y, etc.\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fba576",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 10\n",
    "timesum = 0\n",
    "for i in range(trials):\n",
    "    toc = time.time()\n",
    "    \n",
    "    # All two lines of code submitted for `p2q11` separated by `;`\n",
    "    # solving for beta-hat using the QR decomposition\n",
    "    None\n",
    "    \n",
    "    tic = time.time()\n",
    "    timesum += tic-toc\n",
    "timesum/trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add cells into your notebook but\n",
    "# just don't runtime errors anywhere in your notebook\n",
    "# as cells are run sequentially for automated testing\n",
    "\n",
    "# Automated testing is looking for cells (`cell ids`)\n",
    "# where you're asked to enter answers or complete code \n",
    "# but all other cells like this one or cells you add\n",
    "# are safe to delete if you want a \"cleaner\" notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b300d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71eb88f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
