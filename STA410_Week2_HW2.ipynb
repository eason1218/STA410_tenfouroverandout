{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd079a2e",
   "metadata": {},
   "source": [
    "# STA410 Week 1 Homework (4 points)\n",
    "\n",
    "## Due 12 PM Jan 17 (before class starts)\n",
    "\n",
    "\n",
    "1. **Paired or individual assignment.** Work may be shared within pairs without restriction, but collaborations beyond the pairs must be limited to \"hints\" and may not share complete solutions.\n",
    "\n",
    "2. You are encouraged to adapt code you find available online into your notebook; however, if you do so please provide a link to the utilized resource. ***If failure to cite such references is identified and confirmed, your mark may be reduced.***  \n",
    "\n",
    "3. **Library imports are limited** to only libraries imported in the starter code and the [standard python modules](https://docs.python.org/3/py-modindex.html). Automated code tests that fail because of additional library imports will not recieve credit. Unless a problem instructs differently you may use any functions available from the Python stdlib and the libraries imported in the starter code.\n",
    "\n",
    "<details><summary><span style=\"color: blue; text-decoration: underline; cursor: pointer;\">Additional Details</span></summary>\n",
    "\n",
    "> **Do not delete, replace, or rearranged cells.** This erases `cell ids` upon which automated code tests are based. The \"Edit > Undo Delete Cells\" option in the notebook editor might be helpful; otherwise, redownload the notebook (so it has the correct required `cells ids`) and repopulate it with your answers (assuming you don't overwrite them when you redownload the notebook). ***You may add cells for scratch work*** but if required answers are not submitted through the provided cells where the answers are requested your answers may not be marked. Due to potential problems with `cell ids` **the only environments supported in this class are** [UofT JupyterHub](https://datatools.utoronto.ca/) or [Google Colab](https://colab.research.google.com/)\n",
    ">\n",
    "> **No jupyter shortcut commands** such as `! python script.py 10` or `%%timeit` may be included in the final submission as they will cause subsequent automated code tests to fail.\n",
    ">\n",
    "> **No cells may have any runtime errors** because this causes subsequent automated code tests to fail and you will not get marks for tests which fail because of previous runtime errors. ***Restart and re-run the cells in your notebook to ensure there are no runtime errors before submitting your work.***\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac48101",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Unless otherwise instructed, you may use any functions available \n",
    "# from the following library imports\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9ecd3",
   "metadata": {},
   "source": [
    "## Student and Contribution\n",
    "\n",
    "Are you working with a partner to complete this assignment?  \n",
    "- If not, assign  the value of `None` into the variable `Partner`.\n",
    "- If so, assign the name of the person you worked with into the variable `Partner`.\n",
    "    - Format the name as `\"<First Name> <Last Name>\"` as a `str` type, e.g., \"Scott Schwartz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae98395",
   "metadata": {},
   "outputs": [],
   "source": [
    "Partner = #None\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5e7de",
   "metadata": {},
   "source": [
    "What was your contribution in completing the code for this assignments problems?  \n",
    "Assign one of the following into each of the `Contribution` variable below.\n",
    "\n",
    "- `\"I worked alone\"`\n",
    "- `\"I contributed more than my partner\"`\n",
    "- `\"My partner and I contributed equally\"`\n",
    "- `\"I contributed less than my partner\"`\n",
    "- `\"I did not contribute\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Contribution = #\"I worked alone\"\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a629379",
   "metadata": {},
   "source": [
    "## Part 1: Monte Carlo integration \n",
    "\n",
    "$\\displaystyle \\int h(x) = \\int g(x)f(x) dx = E[g(X)] \\approx \\frac{1}{n}\\sum_{i=1}^n g(x_i) \\quad \\textrm{ for } \\quad x_i \\sim f(X)$ \n",
    "\n",
    "### 1D and 2D versions\n",
    "\n",
    "$\\displaystyle \\int_0^1 g(u_1) du_1 \\quad \\textrm{ and } \\quad \\displaystyle \\int_0^1 \\int_0^1 1_{[u_2 \\leq g(u_1)]}(u_1, u_2) du_1 du_2$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab80cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solving for y in r^2 = x^2 + y^2 \n",
    "g = lambda x: np.sqrt(1-x**2)\n",
    "x = np.linspace(0,1,1000)\n",
    "plt.figure(figsize=(4,4)); plt.title(\"Quarter Circle\")\n",
    "plt.plot(x,g(x));\n",
    "# https://en.wikipedia.org/wiki/Monte_Carlo_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855de84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1q1 = np.pi  # analytical normalizing constant c based on np.pi which makes function c*g a density f\n",
    "p1q2 = integrate.quad(g, 0, 1)  # tuple of the actual and reported error for the area of normalized density f\n",
    "# Using the code provided below...\n",
    "p1q3 = 0  # minimum number of samples MC1 requires to correctly estimate the area under g to 3 decimal places\n",
    "          # with an estimated standard error based on np.std() smaller than 0.0001\n",
    "p1q4 = 0  # minimum number of samples MC2 requires to correctly estimate the area under g to 3 decimal places\n",
    "          # with an estimated standard error based on np.std() smaller than 0.0001\n",
    "p1q5 = 0.0000 # estimated standard deviation of values MC1 averages at the requested sample sizes above\n",
    "p1q6 = 0.0000 # estimated standard deviation of values MC1 averages at the requested sample sizes above\n",
    "p1q7 = \"The least to most efficient method for estimating the area under f appears to be \"+\\\n",
    "       \"integrate.quad -> MC1 -> MC2\"  # correctly order in the provided formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "integrate.quad(g, 0, 1)\n",
    "print(integrate.quad(g, 0, 1))\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "np.random.seed(410); n = 400000\n",
    "u1 = stats.uniform().rvs(n)\n",
    "print(g(u1).mean(),np.pi/4, g(u1).std()/n**0.5)\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "np.random.seed(410);  n=400000\n",
    "u12 = stats.uniform().rvs([n,2])\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0561d7",
   "metadata": {},
   "source": [
    "## Part 2: Monte Carlo Integration with Inverse CDF and Rejection Sampling\n",
    "\n",
    "$\\displaystyle \\int h(x) dx = \\int \\tilde h(x) f(x) dx \\equiv \\int x f(x) dx \\approx \\bar x \\quad \\textrm{ for } \\quad x_i \\sim f(X)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF f the density of g above analytically normalized based on np.pi\n",
    "f = lambda x: None\n",
    "\n",
    "# CDF of f\n",
    "F = lambda x: None\n",
    "\n",
    "@np.vectorize\n",
    "def F_inv(u, F, a=0, b=1, K=50):\n",
    "    # accurate to approximately 0.5**K\n",
    "    x_l,x_r = a,b\n",
    "    F_x_l,F_x_r = 0,1\n",
    "    for k in range(K):\n",
    "        x = (x_l+x_r)/2\n",
    "        F_x = F(x)\n",
    "        if F_x < u:\n",
    "            x_l,F_x_l = x,F_x\n",
    "        else:\n",
    "            x_r,F_x_r = x,F_x\n",
    "    return (x_l+x_r)/2\n",
    "    # confirm with x = F_inv(F_(x))\n",
    "\n",
    "try:\n",
    "    fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "    x = np.linspace(0,1,1000); u=x.copy()\n",
    "    ax[0].plot(x,F(x)); ax[1].plot(u,F_inv(u,F));\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72627bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    h = lambda x: None\n",
    "    plt.figure(figsize=(4,4)); plt.title(\"x*f(x)? The function being integrated?\")\n",
    "    plt.plot(x,h(x)); \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e27d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2q1 = integrate.quad(g, 0, 1)[0]  # expected value of f\n",
    "\n",
    "# Using the code provided below...\n",
    "p2q2 = 0  # minimum number of samples MC1 requires to correctly estimate the area under h to 3 decimal places\n",
    "          # with an estimated standard error based on np.std() smaller than 0.0001\n",
    "p2q3 = 0  # minimum number of samples MC2 requires to correctly estimate the area under h to 3 decimal places\n",
    "          # with an estimated standard error based on np.std() smaller than 0.0001\n",
    "p2q4 = 0.0000  # estimated standard deviation of the values averaged for MC1\n",
    "p2q5 = 0.0000  # estimated standard deviation of the values averaged for MC2\n",
    "\n",
    "p2q6 = \"MC2 <is|is not> rejection sampling\"\n",
    "p2q7 = \"MC2 could be made more efficient by scaling <u1|u2> to be <smaller|larger>\"\n",
    "\n",
    "p2q8 = \"F <does|does not> have an analytical inverse based on transcendental functions\"\n",
    "p2q9 = \"F_inv implements a <bracketing|illinois|Regula falsi|root finding> method\"\n",
    "p2q10 = \"F_inv provides a <numerical|analytical|transcendental> approximation\"\n",
    "\n",
    "# Using the code provided below...\n",
    "p2q11 = 0  # minimum number of inverse CDF based f(X) samples required for same accuracy as above\n",
    "           # with an estimated standard error based on np.std() smaller than 0.001\n",
    "p2q12 = 0  # minimum number of uniform samples required for same accuracy as above based on rejection sampling\n",
    "           # with an estimated standard error based on np.std() smaller than 0.001\n",
    "p2q13 = 0  # the number of f(X) samples produced using rejection sampling\n",
    "p2q14 = 0.0000  # estimated standard deviation of the values averaged for the inverse CDF sampling method\n",
    "p2q15 = 0.0000  # estimated standard deviation of the values averaged for the rejection sampling method\n",
    "\n",
    "# correctly order in the provided formatting\n",
    "p2q16 = \"The least to most efficient computation for estimating the area under f appears to be \"+\\\n",
    "        \"integrate.quad -> MC1 -> MC2 -> inverse CDF sampling -> rejection sampling\"  \n",
    "p2q17 = \"The methods requiring the greatest to least number of uniform samples in order are \"+\\\n",
    "        \"MC1 -> MC2 -> inverse CDF sampling -> rejection sampling\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "integrate.quad(h, 0, 1)\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "np.random.seed(410); n = 30000\n",
    "u1 = stats.uniform().rvs(n)\n",
    "# MC1 method area under h(x)=x*f(x)\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "np.random.seed(410);  n = 30000\n",
    "u12 = stats.uniform().rvs([n,2])\n",
    "# MC2 method area under h(x)=x*f(x) in unit square\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "np.random.seed(410); n = 30000\n",
    "u = stats.uniform().rvs(n)\n",
    "x = None  # Inverse CDF sampling\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "np.random.seed(410);  n = 30000\n",
    "u12 = stats.uniform().rvs([n,2]) \n",
    "# u1 is proposal and c=1.3 for rejection sampling\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72caa727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fig,ax = plt.subplots(1,4,figsize=(10,2.5))\n",
    "    ax[0].hist(MC1_values_being_averaged)\n",
    "    ax[1].hist(MC2_values_being_averaged.astype(int))\n",
    "    ax[2].hist(inverseCDF_values_being_averaged)\n",
    "    ax[3].hist(nonrejection_values_being_averaged)\n",
    "    plt.tight_layout()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934e4d4",
   "metadata": {},
   "source": [
    "## Part 3: Importance Sampling\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\theta = E_f[X] = \\int x f(x) dx = \\displaystyle \\int x \\frac{f(x)}{q(x)} q(x) dx &\\approx{} \\frac{1}{n}\\sum_{i=1}^n w_i^* x_i \\textrm{ for  } x_i \\sim q(X) \\textrm{ with standard error } \\sqrt{\\frac{1}{n}\\textrm{Var}_q(W^*X)} \\\\\n",
    "&\\approx{} \\sum_{i=1}^n w_i x_i \\textrm{ for  } w_i = \\frac{w_i^*}{\\sum_{i=1}^n w_i^*} \\textrm{ and } x_i \\sim q(X)\\\\& {\\textrm{ with delta method approximated standard error }} \\sqrt{\\sum_{i=1}^n w_i^2\\left(x_i - \\sum_{i=1}^n w_ix_i\\right)^2}\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "### Some notes\n",
    "\n",
    "If $q(X) = \\frac{Xf(X)}{\\theta}$ then ${E_q \\left[\\left( \\frac{Xf(X)}{q(X)} - \\theta \\right)^2 \\right]} = 0$ which suggests that $q(X) \\propto Xf(X)$ might be a good idea\n",
    "\n",
    "The **normalized weights** $w_i$ are **random variables** but for *a priori* known weights the ***effective sample size*** $n_{\\text{eff}} = \\frac{1}{\\sum_{i=1}^n w_i^2}$ is maximized at $n$ when $w_i=\\frac{1}{n}$ for all $i$ which suggests that $q(X) = f(X)$ might be a good idea and $q(X)$ should have heavier tails than $f(X)$ so that $\\frac{f(X)}{q(X)}$ does not \"explode\"\n",
    "\n",
    "The ***effective sample size*** $n_{\\text{eff}}$ is derived by equating average and weighted average variance calculations $\\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 = \\sum_{i=1}^n w_i^2\\sigma^2$ and solving for $n$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3q1 = \"<f(x_i)|q(x_i)|f(x_i)/q(x_i)|q(x_i)/f(x_i)> is the obvious natural choice for w*_i\"\n",
    "p3q2 = 0.0  # expected value of W*_i with respect to q(X) for normized density f(X)\n",
    "p3q3 = \"f(x) <must|need not> be a normalized density for the second estimation to work\"\n",
    "\n",
    "# Using the code provided below...\n",
    "p3q4 = 0  # minimum number of q(X) samples required to correctly estimate E_f[x] to 3 decimal places\n",
    "          # using importance sampling based on w*_i\n",
    "          # with an estimated standard error based on np.std() smaller than 0.001\n",
    "p3q5 = 0.0000  # estimated standard deviation of the values averaged to estimate E_f[x] above\n",
    "p3q6 = 0.0000  # sum of w*_i\n",
    "p3q7 = 0.0000  # sum of normalized weights w_i\n",
    "p3q8 = 0  # decimal position where E_f[x] estimate differs if instead done using normalized weights \n",
    "p3q9 = 0.0000000  # delta method approximation of the standard error for this alternative estimate\n",
    "p3q10 = 0.0000  # effective sample size assuming w_i are not random variables\n",
    "\n",
    "p3q11 = \"Effective sample size is <less than|equal to|greater than> the actual sample size \"+\\\n",
    "        \"which is <why|unrelated to why> the standard error estimates are <equal|unequal>\"\n",
    "\n",
    "p3q12 = \"To increase the calcuated effective sample size value the importance weights \"+\\\n",
    "        \"should be made more <homogenous|different> by changing <x|f(x)|q(x)|x*f(x)> \"+\\\n",
    "        \"to be more like <x|f(x)|q(x)|x*f(x)> and less like <x|f(x)|q(x)|x*f(x)>\"\n",
    "\n",
    "p3q13 = \"Increasing the effective sample size <guarantees|may not result in> \"+\\\n",
    "        \"reduced variability in the importance sampling estimate\"\n",
    "\n",
    "p3q14 = \"The variability of interest is that of <x|f(x)|q(x)|x*f(x)|f(x)/q(x)|x*f(x)/q(x)> \"+\\\n",
    "        \"so what we actually want to ensure is that <x|f(x)|q(x)|x*f(x)|f(x)/q(x)|x*f(x)/q(x)> \"+\\\n",
    "        \"never gets exceptionally large compared to <x|f(x)|q(x)|x*f(x)|f(x)/q(x)|x*f(x)/q(x)>\"\n",
    "\n",
    "# For the analyses completed above\n",
    "p3q15 = 0.000  # what fraction of uniform samples were wasted for rejection versus inverse CDF sampling           \n",
    "p3q16 = 0.000000  # importance sampling required what fraction of the samples of the inverse CDF sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba793867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = lambda x: x\n",
    "q = stats.beta(2.0,1.4).pdf\n",
    "fig,ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "x = np.linspace(0,1,1000)\n",
    "ax[0].plot(x, h(x), label=\"x*f(x)\")\n",
    "ax[0].plot(x, 2.275*h(x), label=\"c*x*f(x)\")\n",
    "ax[0].plot(x, q(x), label=\"q(x)\")\n",
    "ax[0].set_title(\"q(x) is closely proportional to x*f(x)\"); ax[0].legend()\n",
    "\n",
    "ax[1].plot(x, f(x), label=\"f(x)\")\n",
    "ax[1].plot(x, q(x), label=\"q(x)\")\n",
    "start = int(0.3*len(x))\n",
    "ax[1].plot(x[start:-1],f(x[start:-1])/q(x[start:-1]), label=\"w* = f(x)/q(x)\")\n",
    "ax[1].set_title(\"q(x) versus f(x)\"); ax[1].legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f08d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "integrate.quad(h, 0, 1)\n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "np.random.seed(410); n = 1000\n",
    "q = stats.beta(2.0,1.4)  # importance sampling \n",
    "tic = time.time()\n",
    "tic-toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41927454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3486b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846900de",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = stats.beta(2.0,1.4)\n",
    "U = stats.uniform()\n",
    "\n",
    "fig,ax = plt.subplots(3,4,figsize=(10,5))\n",
    "x = np.linspace(0,1,1000)\n",
    "ax[0,0].plot(x, h(x), label=\"x*f(x)\")\n",
    "ax[0,0].plot(x, U.pdf(x), label=\"Uniform\")\n",
    "ax[0,0].plot(x, f(x), label=\"f(x)\")\n",
    "ax[0,0].plot(x, q.pdf(x), label=\"q(x)\")\n",
    "ax[0,0].legend()\n",
    "\n",
    "n=10000\n",
    "\n",
    "u = U.rvs(n)\n",
    "ax[0,1].hist(u, density=True)\n",
    "ax[0,1].plot(x, U.pdf(x))\n",
    "ax[0,1].plot(x, h(x))\n",
    "ax[1,1].hist(h(u))\n",
    "\n",
    "x_ = F_inv(u, F)\n",
    "ax[0,2].hist(x_, density=True)\n",
    "ax[0,2].plot(x, f(x))\n",
    "ax[0,2].plot(x, h(x))\n",
    "ax[1,2].hist(x_)\n",
    "\n",
    "x_ = q.rvs(n)\n",
    "w_ = 1+x_*0  # not correct\n",
    "ax[0,3].hist(x_, density=True)\n",
    "ax[0,3].plot(x, q.pdf(x))\n",
    "ax[0,3].plot(x, h(x))\n",
    "ax[0,3].plot(x, f(x), 'k:')\n",
    "ax[1,3].hist(w_*x_)\n",
    "ax[2,3].plot(sorted(np.log(w_)))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c5c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac274e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
